{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import das bibliotecas\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções\n",
    "def imgShow(img, nome):\n",
    "    # Mostra a imagem\n",
    "    cv2.imshow(nome, img)\n",
    "    # Espera que uma tecla seja pressionada\n",
    "    cv2.waitKey(0)\n",
    "    # Limpa a instância do opencv\n",
    "    img.release()\n",
    "    # Fecha a janela\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def mostraInfos(img):\n",
    "    # Mostra imagem\n",
    "    print(\"Matriz da imagem:\")\n",
    "    print (img)\n",
    "    # Mostra as informações da imagem\n",
    "    print(\"Informações da imagem:\")\n",
    "    print (img.shape)\n",
    "    # Mostra o tipo da imagem\n",
    "    print(\"Tipo da imagem:\")\n",
    "    print (type(img))\n",
    "\n",
    "def threshold_binary(img, min, max):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ret, thresh = cv2.threshold(gray, min, max, cv2.THRESH_BINARY)\n",
    "    return thresh\n",
    "\n",
    "# def capShow(cap):\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Leitura de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Começa com a leitura da imagem\n",
    "img = cv2.imread('./media/memes.jfif')\n",
    "# # A imagem é composta por 3 matrizes, uma camada azul, uma verde e outra vermelha, para RGB\n",
    "print (img)\n",
    "# # Imprime uma tupla com a altura, largura e quantidade de camadas da imagem\n",
    "# # 597 pixels de altura, 599 pixels de largura e 3 camadas de imagem\n",
    "print (img.shape)\n",
    "print (type(img))\n",
    "# # Script comumente usando para visualizar a imagem\n",
    "# # Método que mostra a imagem\n",
    "cv2.imshow('image', img)\n",
    "# # Key para quando pressionada feche a imagem\n",
    "cv2.waitKey(0)\n",
    "# # Método para fechar a imagem quando a tecla for pressionada\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando uma flag de leitura em preto e branco\n",
    "img2 = cv2.imread('./media/memes.jfif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "mostraInfos(img2)\n",
    "imgShow(img2, 'imagem')\n",
    "\n",
    "# Salvar a imagem no disco, é possível ler em um formato e salvar em outro\n",
    "cv2.imwrite('output.jpg', img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Personalizando a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenhar nas imagens:\n",
    "img3 = cv2.imread('./media/memes.jfif')\n",
    "# Desenhar uma linha\n",
    "# Passa primeiro a imagem, em seguida a coordenada de inicio, coordenada final, cor, espessura da linha\n",
    "# O plano cartesionado funciona normal para o eixo x e o crescente do y é para baixo:\n",
    "cv2.line(img3, (0,0), (100,100), (255,255,255), 15)\n",
    "# imgShow(img3)\n",
    "\n",
    "# Desenhar shapes\n",
    "# Desenhar um retângulo, mesmos args da linha\n",
    "img4 = cv2.imread('./media/memes.jfif')\n",
    "cv2.rectangle(img4, (0,0), (100,100), (180,40,30), 15)\n",
    "# imgShow(img4)\n",
    "\n",
    "# Desenhar pontos\n",
    "img5 = cv2.imread('./media/memes.jfif')\n",
    "pts = np.array([[10,5], [20,30], [100,140]], np.int32)\n",
    "# Recebe uma imagem, um array com os pontos, para fechar o ultimo ponto com os primeiros, chamamos True, recebe cor e a borda\n",
    "# cv2.polyLines(img5, [pts], True, (0,255,0), 15)\n",
    "# imgShow(img5)\n",
    "\n",
    "# Desenhar circulo\n",
    "img6 = cv2.imread('./media/memes.jfif')\n",
    "# cv2.circle(img6, (0,0), (100,100), (180,40,30), 15)\n",
    "# imgShow(img6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Leitura de vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para armazenar o vídeo em uma variável\n",
    "cap = cv2.VideoCapture('./media/video.mp4')\n",
    "# Para ler a webcam chama-se o index\n",
    "cap2 = cv2.VideoCapture(0)\n",
    "# Para ler a captura\n",
    "while(True):\n",
    "    ok, frame = cap.read()\n",
    "    # Se a imagem não tiver sido lida, o programa vai parar\n",
    "    if not ok:\n",
    "        break\n",
    "    cv2.imshow('frame', frame)\n",
    "    # Aqui ele espera por um evento do teclado, e responde em 100 ms, o ord('q') faz com que quando o q seja pressionado o programa pare\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Limpa o vídeo da memória\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lendo a WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "# Lendo a webcam\n",
    "while(True):\n",
    "    ok2, frame2 = cap2.read()\n",
    "    # Se a imagem não tiver sido lida, o programa vai parar\n",
    "    if not ok2:\n",
    "        break\n",
    "    # Imprime um texto na imagem em todos os frames da imagem\n",
    "    cv2.putText(frame2, \n",
    "               'Hello world', \n",
    "               (100, 50), \n",
    "               cv2.FONT_ITALIC, \n",
    "               1, \n",
    "               (15,30,40), \n",
    "               cv2.LINE_4)\n",
    "    n = n + 1\n",
    "    # Imprimir a quantidade de frames, atualizando a string de frame-a-frame\n",
    "    cv2.putText(frame2, \n",
    "               str(n), \n",
    "               (150, 50), \n",
    "               cv2.FONT_ITALIC, \n",
    "               1, \n",
    "               (150,40,150), \n",
    "               cv2.LINE_4)\n",
    "    # A leitura das cores é (B,G,R)\n",
    "    cv2.imshow('frame', frame2)\n",
    "    # Aqui ele espera por um evento do teclado, e responde em 100 ms, o ord('q') faz com que quando o q seja pressionado o programa pare\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gravando e armazenando vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa condição é importante para processar um vídeo que roda por um algoritmo e não seja real time\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Cria um codec de processamento, simples mas eficaz no windows\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID') # type: ignore\n",
    "# Salva o vídeo, nome, codec, taxa de processamento, tamanho\n",
    "writer = cv2.VideoWriter('out.avi', codec, 20, (640,480))\n",
    "while(True):\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    # Escreve o video no frame\n",
    "    # Basicamente o que ele tá fazendo aqui é gerando um vídeo e salvando ele em uma matriz\n",
    "    writer.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recorte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([\n",
    "    [1,2,3,4,5,6,7,8,9],\n",
    "    [10,20,30,40,50,60,70,80,90],\n",
    "    [100,200,300,400,500,600,700,800,900],\n",
    "    [1000,2000,3000,4000,5000,6000,7000,8000,9000]\n",
    "])\n",
    "# Vai retornar as linas de 0 a 2 sem entrar a 2 e o indice 4\n",
    "croped = matrix[0:2,4]\n",
    "print(croped)\n",
    "img = cv2.imread('./memes.jfif')\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "# Eixo Y, Eixo X\n",
    "croped2 = img[100:400, 50:400]\n",
    "cv2.imshow('image', croped2)\n",
    "cv2.waitKey(0)\n",
    "# E se eu quisesse começar em um ponto e ele fizesse a leitura de 500px a partir daquele ponto\n",
    "y = 100\n",
    "h = 500 # Altura\n",
    "x = 50\n",
    "w = 400 # Largura\n",
    "# Supondo que os pontos iniciais foram pegues através de uma feature\n",
    "croped3 = img[y:y+h, x:x+w]\n",
    "cv2.imshow('image', croped3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Operações matemáticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./media/memes.jfif')\n",
    "show(img)\n",
    "# Percebe-se que as tonalidades da imagem são diferentes\n",
    "# O openCV lê em BGR, enquanto o matplot lê em RGB\n",
    "img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "show(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra as cores em determinado pixel\n",
    "img[55,55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui as cores de um pixel por outras cores\n",
    "img2[55,55] = np.array([0,0,0])\n",
    "show(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui em um intervalo\n",
    "img2[100:300, 100:200] = [255, 255, 255]\n",
    "show(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soma duas imagens\n",
    "res = img * img2\n",
    "show(res)\n",
    "# Subtrai duas imagens\n",
    "res2 = img2 - img\n",
    "show(res2)\n",
    "# Soma duas imagens\n",
    "res = cv2.add(img, img2)\n",
    "show(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Threshold (limiarização) é uma técnica de processamento de imagens que consiste em separar pixels de uma imagem em duas categorias distintas, normalmente preto e branco, a partir de um valor limiar. Esse valor é escolhido com base em características da imagem que se deseja destacar ou ignorar.\n",
    "\n",
    "# Importa imagem\n",
    "res = cv2.imread('./media/memes.jfif')\n",
    "\n",
    "# Converte de BGR para gray\n",
    "gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Converte a imagem para gray a partir da leitura dela\n",
    "gray2 = cv2.imread('./media/memes.jfif' , cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "min = 127\n",
    "max = 255\n",
    "\n",
    "# Aplicando o Thresholding\n",
    "#ret, thresh1 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "# pixel, variável = cv2.threshold(imagem_cinza, menor valor de cor, maior valor de cor, tipo de threshold)\n",
    "ret, thresh1 = cv2.threshold(gray, min, max, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(gray, min, max, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(gray, min, max, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(gray, min, max, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(gray, min, max, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "# Convertendo BGR para RBG para que o matplot imprima\n",
    "res2 = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "titles = ['Normal BGR', 'Normal RGB', 'Cinza', 'Binary', 'Binary Inv', 'Trunc', 'To Zero', 'To Zero Inv']\n",
    "imgs = [res, res2, gray, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.imshow(imgs[i], 'gray', vmin = 0, vmax = 255)\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# cv2.imshow('normal', imgs[0])\n",
    "# cv2.imshow('imagem', gray)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "thresh_types_bgr = cv2.imread('./media/thresholding_types.png')\n",
    "thresh_types = cv2.cvtColor(thresh_types_bgr, cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(1,1,1)\n",
    "plt.imshow(thresh_types, 'gray')\n",
    "plt.title('Tipos de thresholding')\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min = 127\n",
    "max = 255\n",
    "\n",
    "def threshold_binary(gray, min, max):\n",
    "    ret, thresh = cv2.threshold(gray, min, max, cv2.THRESH_BINARY)\n",
    "    return thresh\n",
    "\n",
    "img = cv2.imread('./media/memes.jfif', cv2.IMREAD_GRAYSCALE)\n",
    "thresh = threshold_binary(img, min, max)\n",
    "\n",
    "# Incrementa um borrão na imagem, 5, 7, 9, ..., n\n",
    "img2 = cv2.medianBlur(img, 9)\n",
    "\n",
    "\n",
    "# Os filtros são utilizados para realçar ou suavizar caracteristícas de uma imagem. \n",
    "\n",
    "# Filtro Gaussiano: reduz ruídos, suaviza a imagem e retira detalhes desnecessários.\n",
    "blur = cv2.GaussianBlur(thresh, (5,5), 0)\n",
    "# Parâmetros:\n",
    "# void cv::GaussianBlur\t(\tInputArray \tsrc,\n",
    "#                             OutputArray dst,\n",
    "#                                  Size ksize,\n",
    "#                                 double sigmaX,\n",
    "#                                 double sigmaY = 0,\n",
    "#                                 int borderType = BORDER_DEFAULT,\n",
    "#                                 AlgorithmHint hint = cv::ALGO_HINT_DEFAULT \n",
    "# )\n",
    "\n",
    "# blur = cv2.GaussianBlur(thresh, )\n",
    "\n",
    "titles = ['Cinza', 'Thresholding', 'MedianBlur', 'GaussianBlur']\n",
    "resultados = [img, thresh, img2, blur]\n",
    "\n",
    "for i in range(len(resultados)):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(resultados[i], cmap='gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# for i in range(len(resultados)):\n",
    "#     cv2.imshow(titles[i], resultados[i])\n",
    "\n",
    "\n",
    "# Filtro Laplaciano: Realça as bordas da imagem\n",
    "laplacian = cv2.Laplacian(blur, cv2.CV_64F)\n",
    "# Deve receber a imagem suavizada e um filtro, o utilizado foi padrão 3x3\n",
    "\n",
    "# cv2.imshow('Threshold', thresh)\n",
    "cv2.imshow('Filtro Gaussiano', blur)\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Em casos onde há mais de uma fonte de iluminação pode não ser apropriado colocar um valor global para o Thresholding ([[ret]], thresh = ...), ao invés disso se torna interessante colocar um limiar adaptativo. Onde o algoritmo determina o limite de um pixel com base em uma pequena região ao seu redor. Portanto, obtemos limites diferentes para diferentes regiões da mesma imagem, o que fornece melhores resultados para imagens com iluminação variável.\n",
    "\n",
    "min = 127\n",
    "max = 255\n",
    "blocksize = 11\n",
    "c = 2\n",
    "\n",
    "img = cv2.imread('./media/memes.jfif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Threshold binario\n",
    "ret, th1 = cv2.threshold(img, min, max, cv2.THRESH_BINARY)\n",
    "# Threshold adaptativo\n",
    "th2 = cv2.adaptiveThreshold(img, max, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blocksize, c)\n",
    "th3 = cv2.adaptiveThreshold(img, max, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blocksize, c)\n",
    "# blockSize: Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.\n",
    "# C: Constant subtracted from the mean or weighted mean (see the details below). Normally, it is positive but may be zero or negative as well.\n",
    "\n",
    "titles = ['Cinza', 'Threshold', 'AdaptiveMeanC', 'AdaptiveGaussianC']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# cv2.imshow('Imagem', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diminuir a imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "escalaX = 0.5\n",
    "escalaY = 0.5\n",
    "\n",
    "img = cv2.imread('./media/transform.jpeg')\n",
    "# fx e fy são escalas em porcentagem do tamanho real\n",
    "res = cv2.resize(img, None, fx=escalaX, fy=escalaY, interpolation= cv2.INTER_AREA)\n",
    "# INTER_AREA = Escolher\n",
    "# INTER_CUBIC = ampliar (lento)\n",
    "# INTER_LINEAR = ampliar (rápido)\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('resized', res)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenha em pontos\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./media/transform.jpeg')\n",
    "pts = np.array([[200,5], [20,30], [100,140], [300, 100]], np.int32)\n",
    "cv2.polylines(img, [pts], True, (0,255,0))\n",
    "\n",
    "cv2.imshow('Pontos', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazena coordenadas de pontos definidos pelo usuario\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./media/transform.jpeg')\n",
    "\n",
    "points = []\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if len(points) < 4:\n",
    "            points.append([x, y])\n",
    "            cv2.circle(img, (x,y), 5, (255, 0, 0))\n",
    "\n",
    "cv2.namedWindow('Pontos')\n",
    "cv2.setMouseCallback('Pontos', draw_circle)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Pontos', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformação de perspectiva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "escalaX = 0.5\n",
    "escalaY = 0.5\n",
    "\n",
    "# Ajusta a escala\n",
    "img = cv2.imread('./media/transform.jpeg')\n",
    "img = cv2.resize(img, None, None, fx=escalaX, fy=escalaY, interpolation= cv2.INTER_LINEAR)\n",
    "print(img.shape)\n",
    "\n",
    "# Recolhe os pontos\n",
    "points = []\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if len(points) < 4:\n",
    "            points.append([x, y])\n",
    "            cv2.circle(img, (x,y), 5, (255,0,0), -1)\n",
    "\n",
    "cv2.namedWindow('Pontos')\n",
    "cv2.setMouseCallback('Pontos', draw_circle)\n",
    "\n",
    "while (1):\n",
    "    cv2.imshow('Pontos', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "print(points)\n",
    "\n",
    "# Ele relaciona os pontos, joga o primeiro ponto para o primeiro ponto do outro vetor\n",
    "points = np.float32(points)\n",
    "pts2 = np.float32([[0,0], [450,0], [0,800], [450,800]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(points, pts2)\n",
    "dst = cv2.warpPerspective(img, M, (450,800))\n",
    "\n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Output', dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Object Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take each frame of the video\n",
    "2. Convert from BGR to HSV color-space\n",
    "3. We threshold the HSV image for a range of blue color\n",
    "4. Now extract the blue object alone, we can do whatever we want on that image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Defina a cor em formato BGR (Blue, Green, Red)\n",
    "color = np.uint8([[[0, 255, 0]]]) # A matriz agora é 1x1x3\n",
    "\n",
    "# Converta a cor de BGR para HSV\n",
    "hsv_color = cv2.cvtColor(color, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Imprima o resultado\n",
    "print(hsv_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    # 1. Leitura do vídeo\n",
    "    _, frame = capture.read()\n",
    "\n",
    "    # 2. Converte de BGR para HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define a escala das cores do Threshold em escala HSV\n",
    "    # A ideia é que todas as cores abaixo do intervalo ou acima não estarão sendo indentificadas\n",
    "    lower_blue = np.array([106,5,102])\n",
    "    upper_blue = np.array([147,255,255])\n",
    "\n",
    "    # 3. Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Erosão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia básica de erosão é apenas como a erosão do solo, ela corrói os limites do objeto em primeiro plano (sempre tente manter o primeiro plano em branco). Então, o que ele faz? O kernel desliza pela imagem (como na convolução 2D). Um pixel na imagem original (1 ou 0) será considerado 1 somente se todos os pixels sob o kernel forem 1, caso contrário, ele será erodido (feito a zero).\n",
    "\n",
    "Então, o que acontece é que todos os pixels próximos ao limite serão descartados dependendo do tamanho do kernel. Portanto, a espessura ou o tamanho do objeto em primeiro plano diminui ou simplesmente a região branca diminui na imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./media/erosion.png', cv2.IMREAD_GRAYSCALE)\n",
    "ret, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Criação do Kernel\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "erosion = cv2.erode(thresh, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow('erosion', erosion)\n",
    "cv2.imshow('imagem', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    erosion = cv2.erode(thresh, kernel, iterations=1)\n",
    "\n",
    "    cv2.imshow('Erosion', erosion)\n",
    "    cv2.imshow('Thresh', thresh)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Canny Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A detecção de bordas de Canny (Canny Edge Detection) é um dos algoritmos mais populares e amplamente utilizados na visão computacional para a detecção de bordas em imagens. Desenvolvido por John F. Canny em 1986, o objetivo principal desse algoritmo é identificar bordas significativas em uma imagem, ou seja, regiões onde há uma variação abrupta na intensidade de pixels, o que normalmente corresponde aos contornos de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./media/memes.jfif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "edges = cv2.Canny(img,130,200)\n",
    "\n",
    "cv2.imshow('Canny', edges)\n",
    "cv2.imshow('Normal', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    edges = cv2.Canny(frame,130,200)\n",
    "\n",
    "    cv2.imshow('Canny', edges)\n",
    "    cv2.imshow('Normal', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 1) # Tratamento de ruidos\n",
    "    #r, thresh = cv2.threshold(blur, 127, 255, cv2.THRESH_BINARY) # Binarizou \n",
    "    erosion = cv2.erode(blur, kernel, iterations=1) # Tratamento dos ruidos brancos\n",
    "    edges = cv2.Canny(erosion,130,200) # Bordas e ruídos\n",
    "\n",
    "    # cv2.imshow('Thresh', thresh)\n",
    "    cv2.imshow('Canny', edges)\n",
    "    cv2.imshow('Erosion', erosion)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Contornos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contours can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity. The contours are a useful tool for shape analysis and object detection and recognition.\n",
    "\n",
    "- For better accuracy, use binary images. So before finding contours, apply threshold or canny edge detection.\n",
    "- Since OpenCV 3.2, findContours() no longer modifies the source image.\n",
    "- In OpenCV, finding contours is like finding white object from black background. So remember, object to be found should be white and background should be black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./media/memes.jfif')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, 0, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours2, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "mostrar = cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "mostrar2 = cv2.drawContours(img, contours2, -1, (0,255,0), 3)\n",
    "\n",
    "# cv2.imshow('Contornos', thresh)\n",
    "cv2.imshow('Mostrar', mostrar)\n",
    "cv2.imshow('Mostrar2', mostrar2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#gray = cv2.cvtColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    cap_ = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, thresh = cv2.threshold(cap_, 127, 255, 0)\n",
    "    contours1, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    mostrar1 = cv2.drawContours(frame, contours1, -1, (0,255,0), -2)\n",
    "\n",
    "    cv2.imshow('Gray', cap_)\n",
    "    cv2.imshow('Gray', thresh)\n",
    "    cv2.imshow('Mostrar1', mostrar1)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. HughLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Captura de vídeo\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Converter para escala de cinza\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar bordas usando Canny\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Detectar linhas usando Hough Transform Probabilística\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=30, minLineLength=10, maxLineGap=40)\n",
    "\n",
    "    # Desenhar as linhas detectadas na imagem\n",
    "    if lines is not None:\n",
    "        for x1, y1, x2, y2 in lines[:, 0]:\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    # Exibir o quadro resultante\n",
    "    cv2.imshow('Linhas detectadas', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar a captura e fechar janelas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Captura de vídeo\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Converter para escala de cinza\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar bordas usando Canny\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Detectar linhas usando Hough Transform (Método Padrão)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
    "\n",
    "    # Desenhar as linhas detectadas na imagem\n",
    "    if lines is not None:\n",
    "        for rho, theta in lines[:, 0]:\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    # Exibir o quadro resultante\n",
    "    cv2.imshow('Linhas detectadas', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar a captura e fechar janelas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_paper_contour(frame):\n",
    "    \"\"\" Detecta a folha de papel e retorna o contorno e a máscara. \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assumir que o maior contorno é a folha de papel\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        mask = np.zeros_like(gray)\n",
    "        cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "        return largest_contour, mask\n",
    "    return None, None\n",
    "\n",
    "# Captura de vídeo\n",
    "cap = cv2.VideoCapture(0)  # 0 para câmera padrão, ou caminho para um vídeo\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Encontrar o contorno da folha e a máscara\n",
    "    contour, mask = find_paper_contour(frame)\n",
    "\n",
    "    if mask is not None:\n",
    "        # Detecção de bordas\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "        # Detectar linhas usando Hough Transform\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=10)\n",
    "\n",
    "        if lines is not None:\n",
    "            for x1, y1, x2, y2 in lines[:, 0]:\n",
    "                # Verificar se ambos os pontos da linha estão dentro da máscara\n",
    "                if mask[y1, x1] and mask[y2, x2]:\n",
    "                    cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Desenhar o contorno da folha\n",
    "        if contour is not None:\n",
    "            cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Exibir o quadro resultante\n",
    "    cv2.imshow('Linhas detectadas', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar a captura e fechar janelas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2 Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./media/memes.jfif')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Sem o median blur\n",
    "minThresh = 127\n",
    "maxThresh = 255\n",
    "_, thresh = cv2.threshold(gray, minThresh, maxThresh, cv2.THRESH_BINARY)\n",
    "\n",
    "# Erosões\n",
    "qntErosions = 3\n",
    "iterations = [3,30,300]\n",
    "kernelSize = (1,1)\n",
    "\n",
    "# Canny\n",
    "threshMin = 100\n",
    "threshMax = 200\n",
    "\n",
    "# Plot imagens\n",
    "linhas = 2\n",
    "col = 3\n",
    "\n",
    "img_erosion = []\n",
    "img_edges = []\n",
    "\n",
    "kernel = np.ones(kernelSize, np.uint8)\n",
    "for i in range(qntErosions):\n",
    "    erosion = cv2.erode(thresh, kernel, iterations= iterations[i])\n",
    "    img_erosion.append(erosion)\n",
    "    edge = cv2.Canny(erosion, threshMin, threshMax)\n",
    "    img_edges.append(edge)\n",
    "\n",
    "j = 0\n",
    "for i in range(linhas*col):\n",
    "    plt.subplot(linhas, col, i+1)\n",
    "    if i + 1 <= 3:\n",
    "        plt.imshow(img_erosion[i], cmap='gray')\n",
    "        plt.title(f'Interações: {iterations[i]}')\n",
    "    if i + 1 > 3:\n",
    "        plt.imshow(img_edges[j], cmap='gray')\n",
    "        plt.title(f'Interações: {iterations[j]}')\n",
    "        j += 1\n",
    "\n",
    "# Bordas da imagem\n",
    "edges = cv2.Canny(img,130,200)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# cv2.imshow('teste', img_edges[0])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./media/br.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold\n",
    "minThresh = 150\n",
    "maxThresh = 255\n",
    "_, thresh = cv2.threshold(gray, minThresh, maxThresh, cv2.THRESH_BINARY)\n",
    "\n",
    "# Kernel\n",
    "kernelSize = (1,1)\n",
    "kernel = np.ones(kernelSize, np.uint8)\n",
    "\n",
    "# Erosion\n",
    "iterations = 1\n",
    "erosion = cv2.erode(thresh, kernel, iterations= iterations)\n",
    "\n",
    "# Canny\n",
    "threshMin = 100\n",
    "threshMax = 200\n",
    "aperture = 3\n",
    "edge = cv2.Canny(erosion, threshMin, threshMax, apertureSize= aperture)\n",
    "\n",
    "# Houghlines\n",
    "rho_ = 1\n",
    "thresh_ = 100\n",
    "minLenght = 20\n",
    "maxGap = 5\n",
    "lines = cv2.HoughLinesP(edge,rho_,np.pi/180, thresh_,minLineLength=minLenght,maxLineGap=maxGap)\n",
    "\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "else:\n",
    "    print(\"Nenhuma linha foi detectada.\")\n",
    "\n",
    "mostrar = [thresh, erosion, edge, img]\n",
    "titles = ['thresh', 'erosion', 'edge', 'img']\n",
    "linhas = 2\n",
    "colunas = 2\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(mostrar)):\n",
    "    if i+1 >= 1:\n",
    "        plt.subplot(linhas, colunas, i+1)\n",
    "        plt.imshow(mostrar[i], cmap='gray')\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Gray', gray)\n",
    "cv2.imshow('Thresh', thresh)\n",
    "cv2.imshow('Erosion', erosion)\n",
    "cv2.imshow('Edge', edge)\n",
    "cv2.imshow('Final', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./media/linhas/1.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "equalization_gray = cv2.equalizeHist(gray)\n",
    "\n",
    "# print(img.shape)\n",
    "# mask = np.zeros(img.shape[:2], np.uint8)\n",
    "# mask[480:960, 0:1280] = 255\n",
    "# masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "\n",
    "# Threshold\n",
    "minThresh = 80\n",
    "maxThresh = 255\n",
    "_, thresh = cv2.threshold(gray, minThresh, maxThresh, cv2.THRESH_BINARY)\n",
    "\n",
    "# Kernel\n",
    "kernelSize = (1,1)\n",
    "kernel = np.ones(kernelSize, np.uint8)\n",
    "\n",
    "# Erosion\n",
    "iterations = 1\n",
    "erosion = cv2.erode(thresh, kernel, iterations= iterations)\n",
    "\n",
    "# Canny\n",
    "threshMin = 100\n",
    "threshMax = 200\n",
    "aperture = 3\n",
    "edge = cv2.Canny(erosion, threshMin, threshMax, apertureSize= aperture)\n",
    "\n",
    "# Hughlines\n",
    "rho_ = 1\n",
    "thresh_ = 100\n",
    "minLenght = 10\n",
    "maxGap = 5\n",
    "lines = cv2.HoughLinesP(edge,rho_,np.pi/180, thresh_,minLineLength=minLenght,maxLineGap=maxGap)\n",
    "\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "else:\n",
    "    print(\"Nenhuma linha foi detectada.\")\n",
    "\n",
    "mostrar = [gray, equalization_gray, thresh, erosion, edge, img]\n",
    "titles = ['gray', 'equalizado', 'thresh', 'erosion', 'edge', 'img']\n",
    "linhas = 3\n",
    "colunas = 2\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(mostrar)):\n",
    "    if i+1 >= 1:\n",
    "        plt.subplot(linhas, colunas, i+1)\n",
    "        plt.imshow(mostrar[i], cmap='gray')\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "Proposta:\n",
    "    - Auto ajuste do thresholding. \n",
    "        Possível solução:\n",
    "            Diminuir/Aumentar valor de acordo com a quantidade de linhas detectadas dentro de uma máscara.\n",
    "                Local da máscara:\n",
    "                    Visão ocular do motorista.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture('./media/linhas/video_teste.mp4')\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    _, norm = cap.read()\n",
    "\n",
    "    escalaX = 0.2\n",
    "    escalaY = 0.2\n",
    "    frame = cv2.resize(frame, None, fx=escalaX, fy=escalaY, interpolation= cv2.INTER_AREA)\n",
    "    norm = cv2.resize(norm, None, fx=escalaX, fy=escalaY, interpolation= cv2.INTER_AREA)\n",
    "\n",
    "    # Convertendo de BGR para HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Filtros de cores\n",
    "    # Amarelo\n",
    "    lower_yellow = np.array([20,50,70])\n",
    "    upper_yellow = np.array([35,255,255])\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    # Branco\n",
    "    lower_white = np.array([0, 0, 130])\n",
    "    upper_white = np.array([130,25,255])\n",
    "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    # Resultado do filtro\n",
    "    combined_mask = cv2.bitwise_or(mask_yellow, mask_white)\n",
    "    result = cv2.bitwise_or(frame, frame, mask=combined_mask)\n",
    "\n",
    "    # Imagem cinza\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Histograma equalizado\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    # Thresh para binário\n",
    "    _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "    # Erosão - Diminuição das linhas brancas\n",
    "    erosion = cv2.erode(thresh, (3,3), iterations=1)\n",
    "    # Testar aplicando a dilatação\n",
    "    \n",
    "    # Bordas da imagem\n",
    "    edges = cv2.Canny(erosion, 127, 255)\n",
    "    # Inserindo as linhas\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 127, minLineLength=5, maxLineGap=30)\n",
    "\n",
    "    # Caso nenhuma linha tenha sido detectada\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    else:\n",
    "        print(\"Nenhuma linha foi detectada.\")\n",
    "\n",
    "    # Resultado das imagens\n",
    "    # cv2.imshow('Branca', mask_white)\n",
    "    # cv2.imshow('Amarela', mask_yellow)\n",
    "    cv2.imshow('Edges', edges)\n",
    "    cv2.imshow('original', norm)\n",
    "    # Resultado do bitwise    \n",
    "    cv2.imshow('Máscaras', result)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Função de callback para as trackbars\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Função para atualizar a imagem com base nos valores das trackbars\n",
    "def update_image():\n",
    "    # Ler a imagem\n",
    "    img = cv2.imread('./road.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "   \n",
    "    # Converter a imagem para escala de cinza\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "   \n",
    "    # Obter valores das trackbars\n",
    "    threshold1 = cv2.getTrackbarPos('Threshold 1', 'Trackbars')\n",
    "    threshold2 = cv2.getTrackbarPos('Threshold 2', 'Trackbars')\n",
    "    erosion_size = cv2.getTrackbarPos('Erosion Size', 'Trackbars')\n",
    "   \n",
    "    # Aplicar o thresholding\n",
    "    _, thresh = cv2.threshold(gray, threshold1, threshold2, cv2.THRESH_BINARY)\n",
    "   \n",
    "    # Aplicar a erosão\n",
    "    kernel = np.ones((erosion_size, erosion_size), np.uint8)\n",
    "    eroded = cv2.erode(thresh, kernel, iterations=1)\n",
    "   \n",
    "    # Criar a área para as trackbars (painel lateral)\n",
    "    height, width = img.shape[:2]\n",
    "    panel_height = height\n",
    "    panel_width = 200  # Largura do painel lateral\n",
    "    panel = np.zeros((panel_height, panel_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Mostrar a imagem processada\n",
    "    cv2.imshow('Processed Image', eroded)\n",
    "\n",
    "    # Atualizar a imagem do painel\n",
    "    cv2.imshow('Trackbars', panel)\n",
    "\n",
    "# Função para salvar os valores das trackbars em um arquivo JSON\n",
    "def save_values():\n",
    "    values = {\n",
    "        'Threshold 1': cv2.getTrackbarPos('Threshold 1', 'Trackbars'),\n",
    "        'Threshold 2': cv2.getTrackbarPos('Threshold 2', 'Trackbars'),\n",
    "        'Erosion Size': cv2.getTrackbarPos('Erosion Size', 'Trackbars')\n",
    "    }\n",
    "    with open('trackbar_values.json', 'w') as f:\n",
    "        json.dump(values, f)\n",
    "\n",
    "# Função para carregar os valores das trackbars a partir de um arquivo JSON\n",
    "def load_values():\n",
    "    if os.path.exists('trackbar_values.json'):\n",
    "        with open('trackbar_values.json', 'r') as f:\n",
    "            values = json.load(f)\n",
    "            cv2.setTrackbarPos('Threshold 1', 'Trackbars', values.get('Threshold 1', 0))\n",
    "            cv2.setTrackbarPos('Threshold 2', 'Trackbars', values.get('Threshold 2', 255))\n",
    "            cv2.setTrackbarPos('Erosion Size', 'Trackbars', values.get('Erosion Size', 1))\n",
    "\n",
    "# Criar a janela para a imagem\n",
    "cv2.namedWindow('Processed Image')\n",
    "\n",
    "# Criar a janela para o painel de trackbars\n",
    "cv2.namedWindow('Trackbars', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Trackbars', 200, 600)\n",
    "\n",
    "# Criar as trackbars na janela 'Trackbars'\n",
    "cv2.createTrackbar('Threshold 1', 'Trackbars', 0, 255, nothing)\n",
    "cv2.createTrackbar('Threshold 2', 'Trackbars', 255, 255, nothing)\n",
    "cv2.createTrackbar('Erosion Size', 'Trackbars', 1, 20, nothing)\n",
    "\n",
    "# Carregar valores anteriores, se existirem\n",
    "load_values()\n",
    "\n",
    "while True:\n",
    "    update_image()\n",
    "   \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "    elif key == ord('s'):  # 's' key to save values\n",
    "        save_values()\n",
    "\n",
    "# Fechar todas as janelas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Carregando a imagem\n",
    "img = cv2.imread('./media/road.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Trackbar Threshold\n",
    "cv2.namedWindow('Threshold')\n",
    "cv2.resizeWindow('Threshold', 600, 75)\n",
    "cv2.createTrackbar('thresh_value', 'Threshold', 0,255, nothing)\n",
    "cv2.createTrackbar('max_value', 'Threshold', 0,255, nothing)\n",
    "\n",
    "# Trackbar Erosion\n",
    "cv2.namedWindow('Erosion')\n",
    "cv2.resizeWindow('Erosion', 600, 75)\n",
    "cv2.createTrackbar('kernel_size', 'Erosion', 1,15, nothing)\n",
    "cv2.createTrackbar('iterations', 'Erosion', 0,10, nothing)\n",
    "\n",
    "# Trackbar Bordas\n",
    "cv2.namedWindow('Edges')\n",
    "cv2.resizeWindow('Edges', 600, 120)\n",
    "cv2.createTrackbar('min_value', 'Edges', 0,255, nothing)\n",
    "cv2.createTrackbar('max_value', 'Edges', 0,255, nothing)\n",
    "cv2.createTrackbar('aperture', 'Edges', 3,7, nothing)\n",
    "\n",
    "# Trackbar Linhas\n",
    "cv2.namedWindow('Linhas')\n",
    "cv2.resizeWindow('Linhas', 600, 150)\n",
    "cv2.createTrackbar('rho', 'Linhas', 1,100, nothing)\n",
    "cv2.createTrackbar('thresh_hough', 'Linhas', 0,255, nothing)\n",
    "cv2.createTrackbar('minLenght', 'Linhas', 0,100, nothing)\n",
    "cv2.createTrackbar('maxGap', 'Linhas', 0,100, nothing)\n",
    "\n",
    "while True:\n",
    "    # Thresh\n",
    "    thresh_value = cv2.getTrackbarPos('thresh_value', 'Threshold')\n",
    "    max_value = cv2.getTrackbarPos('max_value', 'Threshold')\n",
    "    _, thresh = cv2.threshold(gray, thresh_value, max_value, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Erosão\n",
    "    k = cv2.getTrackbarPos('kernel_size', 'Erosion')\n",
    "    kernel_value = (k,k)\n",
    "    iterarions_value = cv2.getTrackbarPos('iterations', 'Erosion')\n",
    "    erode = cv2.erode(thresh, kernel_value, iterations=iterarions_value)\n",
    "\n",
    "    # Bordas\n",
    "    min_value = cv2.getTrackbarPos('min_value', 'Edges')\n",
    "    max_value = cv2.getTrackbarPos('max_value', 'Edges')\n",
    "    aperture = cv2.getTrackbarPos('aperture', 'Edges')\n",
    "    edges = cv2.Canny(erode, min_value, max_value, apertureSize=aperture)\n",
    "\n",
    "    # Linhas\n",
    "    rho_value = cv2.getTrackbarPos('rho', 'Linhas')\n",
    "    thresh_hough = cv2.getTrackbarPos('thresh_hough', 'Linhas')\n",
    "    minLenght = cv2.getTrackbarPos('minLenght', 'Linhas')\n",
    "    maxGap = cv2.getTrackbarPos('maxGap', 'Linhas')\n",
    "    lines = []\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "        lines = cv2.HoughLinesP(edges,rho_value,np.pi/180, thresh_hough,minLineLength=minLenght,maxLineGap=maxGap)\n",
    "\n",
    "    if lines is not None:\n",
    "        img_copy = img.copy()\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    else:\n",
    "        print(\"Nenhuma linha foi detectada.\")\n",
    "\n",
    "    cv2.imshow('Imagem', img_copy)\n",
    "    cv2.imshow('Bordas', edges)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
